{
  "version": "0.1",
  "type": "container",
  "meta": {
    "trigger": "benchmark"
  },
  "ops": [
    {
      "type": "container/run",
      "id": "lmdepoy_llama_70b_4x",
      "args": {
        "cmd": [
          "/bin/sh",
          "-c",
          "lmdeploy serve api_server ../../root/snapshots/2123003760781134cfc31124aa6560a45b491fdf --model-name llama3.1_70B_4x --chat-template /chat_template.json --model-format awq"
        ],
        "image": "docker.io/openmmlab/lmdeploy:latest",
        "gpu": true,
        "expose": 23333,
        "resources": [
          {
            "type": "S3",
            "url": "https://models.nosana.io/hugging-face/llama3.1/70b/4x/models--hugging-quants--Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
            "target": "/root/"
          }
        ]
      }
    }
  ]
}