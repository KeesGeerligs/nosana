{
    "version": "0.1",
    "type": "container",
    "meta": {
      "trigger": "cli"
    },
    "ops": [
      {
        "type": "container/run",
        "id": "LMDeploy-llama3.1",
        "args": {
          "cmd": [
            "/bin/sh",
            "-c",
            "echo \"Starting lmdeploy service...\"; lmdeploy serve api_server ../../root/snapshots/db1f81ad4b8c7e39777509fac66c652eb0a52f91 --model-name llama3.1_8B_4x --chat-template /chat_template.json --model-format awq"
          ],
          "image": "docker.io/nosana/llm_benchmark-lmdeploy:0.2.0.1",
          "gpu": true,
          "expose": 23333,
          "resources": [
            {
              "type": "S3",
              "url": "https://models.nosana.io/hugging-face/llama3.1/8b/4x/models--hugging-quants--Meta-Llama-3.1-8B-Instruct-AWQ-INT4",
              "target": "/root/"
            }
          ]
        }
      }
    ]
  }
  