{
  "version": "0.1",
  "type": "container",
  "meta": {
    "trigger": "cli"
  },
  "ops": [
    {
      "type": "container/run",
      "id": "VLLM-llama3.1",
      "args": {
        "cmd": [
          "--model",
          "/root/.cache/huggingface/hub/models--unsloth--Meta-Llama-3.1-8B/snapshots/069adfb3ab0ceba60b9af8f11fa51558b9f9d396",
          "--served-model-name",
          "llama3.1"
        ],
        "image": "docker.io/vllm/vllm-openai:v0.5.4",
        "gpu": true,
        "expose": 8000,
        "resources": [
          {
            "type": "S3",
            "url": "s3://nos-ai-models-qllsn32u/hugging-face/llama3.1/8b/models--unsloth--Meta-Llama-3.1-8B",
            "target": "/root/.cache/huggingface/hub/models--unsloth--Meta-Llama-3.1-8B"
          }
        ]
      }
    }
  ]
}