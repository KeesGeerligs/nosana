{
  "version": "0.1",
  "type": "container",
  "meta": {
    "trigger": "cli"
  },
  "ops": [
    {
      "type": "container/run",
      "id": "VLLM",
      "args": {
        "cmd": [
          "-c ",
          "timeout 110m",
          " python3 -m vllm.entrypoints.openai.api_server",
          " --model TheBloke/LLaMA-Pro-8B-AWQ",
          " --quantization awq"], 
        "entrypoint": "/bin/sh",
        "image": "vllm/vllm-openai:latest",
        "gpu": true,
        "expose": 8000,
        "env": {
          "HUGGING_FACE_HUB_TOKEN": "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"
        }
      }
    }
  ]
}


